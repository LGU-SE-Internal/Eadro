# Eadro 模型输入输出及数据适配计划

## 项目概览
Eadro 是一个基于多源数据（日志、指标、链路追踪）的故障检测和定位模型，使用图神经网络和时序卷积网络进行特征提取和融合。

## 现有模型架构分析

### 1. 模型整体结构
主模型 `MainModel` 包含以下核心组件：
- **MultiSourceEncoder**: 多源数据编码器
- **Detecter**: 故障检测器（二分类：正常/异常）
- **Localizer**: 故障定位器（多分类：定位到具体节点）

### 2. 现有模型输入格式

#### 2.1 数据结构
模型接受以下格式的输入：
- **Graph**: DGL图结构，包含节点数据
- **fault_indexs**: 故障节点标签 (Tensor)

#### 2.2 Graph节点数据格式
每个图节点包含三种数据：
```python
graph.ndata["logs"]     # [batch_size*node_num, event_num] - 日志事件特征
graph.ndata["metrics"]  # [batch_size*node_num, chunk_length, metric_num] - 指标时序数据  
graph.ndata["traces"]   # [batch_size*node_num, chunk_length, 1] - 链路延迟数据
```

#### 2.3 具体维度说明
- `event_num`: 日志事件模板数量
- `metric_num`: 指标特征数量
- `node_num`: 系统节点数量
- `chunk_length`: 时间窗口长度（默认10）
- `batch_size`: 批次大小

### 3. 现有模型输出格式

#### 3.1 训练阶段输出
```python
{
    "loss": 总损失（检测损失 + 定位损失）,
    "y_pred": 预测的故障节点列表,
    "y_prob": 真实标签概率矩阵 [batch_size, node_num],
    "pred_prob": 预测概率矩阵 [batch_size, node_num]
}
```

#### 3.2 推理阶段输出
- 故障检测：二分类结果（正常/异常）
- 故障定位：节点排序列表（按故障概率降序）

### 4. 模型组件详细分析

#### 4.1 TraceModel（链路模型）
- **输入**: `[batch_size, chunk_length, 1]` - 延迟时序数据
- **结构**: 1D卷积网络 + 可选自注意力
- **输出**: `[batch_size, trace_hidden_dim]` - 链路特征向量

#### 4.2 MetricModel（指标模型）
- **输入**: `[batch_size, chunk_length, metric_num]` - 指标时序数据
- **结构**: 1D卷积网络 + 可选自注意力
- **输出**: `[batch_size, metric_hidden_dim]` - 指标特征向量

#### 4.3 LogModel（日志模型）
- **输入**: `[batch_size, event_num]` - 日志事件特征
- **结构**: 线性变换层
- **输出**: `[batch_size, log_dim]` - 日志特征向量

#### 4.4 GraphModel（图模型）
- **输入**: 融合后的节点特征
- **结构**: GAT图注意力网络 + 全局池化
- **输出**: `[batch_size, graph_hidden_dim]` - 图级特征向量

## 新数据格式分析

根据 `main.py` 中的示例数据，新数据包含以下格式：

### 1. 指标数据（Metrics）
```
列名: time, metric, value, service_name, attr.k8s.node.name, attr.k8s.namespace.name, 
      attr.k8s.statefulset.name, attr.k8s.deployment.name, attr.k8s.replicaset.name,
      attr.k8s.pod.name, attr.k8s.container.name
示例: container.memory.major_page_faults = 0.0
```

### 2. 日志数据（Logs）
```
列名: time, trace_id, span_id, level, service_name, message, 
      attr.k8s.pod.name, attr.k8s.service.name, attr.k8s.namespace.name
示例: Spring DispatcherServlet 初始化日志
```

### 3. 链路数据（Traces）
```
列名: time, trace_id, span_id, parent_span_id, span_name, attr.span_kind,
      service_name, duration, attr.status_code, attr.k8s.pod.name,
      attr.k8s.service.name, attr.k8s.namespace.name, 
      attr.http.request.content_length, attr.http.response.content_length,
      attr.http.request.method, attr.http.response.status_code
示例: GET /api/v1/configservice/configs/{configName}, duration=1166528342
```

## 数据适配计划

### 1. 数据预处理适配

#### 1.1 服务节点映射
- **目标**: 建立 `service_name` 到节点 ID 的映射
- **方法**: 从所有数据源提取唯一的 `service_name`，建立 `service2node_id` 映射表
- **输出**: `node_num` 个服务节点

#### 1.2 时间窗口切分
- **目标**: 将连续时间数据切分为固定长度的时间窗口
- **方法**: 按时间顺序切分为 `chunk_length=10` 的时间片段
- **输出**: 多个时间窗口的数据片段

#### 1.3 指标数据处理
```python
# 新数据适配流程
def process_metrics(df_metrics, service2node_id, intervals):
    """
    输入: 
    - df_metrics: 原始指标DataFrame
    - service2node_id: 服务到节点ID映射
    - intervals: 时间窗口列表
    
    输出:
    - metrics_chunks: [chunk_num, node_num, chunk_length, metric_num]
    """
    # 1. 按service_name分组
    # 2. 按时间窗口切分
    # 3. 提取metric值构建时序矩阵
    # 4. 标准化处理
```

#### 1.4 日志数据处理
```python
def process_logs(df_logs, service2node_id, intervals):
    """
    输入:
    - df_logs: 原始日志DataFrame
    - service2node_id: 服务到节点ID映射
    - intervals: 时间窗口列表
    
    输出:
    - logs_chunks: [chunk_num, node_num, event_num]
    """
    # 1. 提取日志模板（基于message字段）
    # 2. 使用Hawkes过程建模日志强度
    # 3. 按服务和时间窗口聚合
```

#### 1.5 链路数据处理
```python
def process_traces(df_traces, service2node_id, intervals):
    """
    输入:
    - df_traces: 原始链路DataFrame
    - service2node_id: 服务到节点ID映射
    - intervals: 时间窗口列表
    
    输出:
    - traces_chunks: [chunk_num, node_num, chunk_length, 1]
    """
    # 1. 按service_name分组
    # 2. 提取duration作为延迟特征
    # 3. 按时间窗口聚合平均延迟
```

### 2. 图结构构建

#### 2.1 服务依赖图构建
```python
def build_service_graph(df_traces):
    """
    基于链路追踪数据构建服务调用图
    
    输入: df_traces (包含parent_span_id和span_id)
    输出: edges [(source_node, target_node), ...]
    """
    # 1. 基于parent_span_id -> span_id构建调用关系
    # 2. 映射到service级别的调用图
    # 3. 转换为DGL图格式
```

### 3. 标签处理

#### 3.1 异常标签生成
- **方法1**: 基于现有业务知识标注异常时间段
- **方法2**: 基于指标阈值或日志错误级别自动标注
- **方法3**: 使用无监督异常检测方法生成伪标签

### 4. 数据管道适配

#### 4.1 数据加载器修改
```python
class NewChunkDataset(Dataset):
    def __init__(self, data_pack_path, chunk_length=10):
        """
        适配新数据格式的数据集类
        
        输入: data_pack_path - 数据包路径（包含parquet文件）
        """
        # 1. 加载parquet文件
        # 2. 预处理生成chunks
        # 3. 构建图结构
```

#### 4.2 模型参数适配
```python
# 需要根据新数据更新的参数
model_params = {
    'event_num': len(log_templates),      # 从日志数据提取
    'metric_num': len(unique_metrics),    # 从指标数据提取  
    'node_num': len(unique_services),     # 从服务名提取
    'chunk_length': 10,                   # 保持不变
}
```

## 代码规范化改进计划

### 1. 修复现有代码错误
- 修复 `model.py` 中的属性名错误（`locator` -> `localizer`, `detector` -> `detecter`）
- 修复未定义变量（`trace_dropout`, `metric_dropout`）
- 修复类型注解错误（`torch.tensor` -> `torch.Tensor`）
- 调整导入语句位置

### 2. 代码风格改进
- 统一命名规范（PEP8）
- 添加类型提示和文档字符串
- 模块化重构（将预处理代码独立成模块）
- 添加配置文件管理

### 3. 项目结构优化
```
Eadro/
├── config/                 # 配置文件
├── data/                   # 数据目录
├── models/                 # 模型定义
├── preprocessing/          # 数据预处理
├── utils/                  # 工具函数
├── experiments/            # 实验脚本
└── docs/                   # 文档
```

## 实施步骤

### 阶段1：数据适配
1. 实现新数据格式的解析和预处理
2. 构建服务调用图
3. 生成训练数据格式

### 阶段2：代码重构
1. 修复现有模型代码错误
2. 改进代码风格和结构
3. 添加配置管理

### 阶段3：模型验证
1. 使用新数据训练模型
2. 验证模型性能
3. 调优超参数

### 阶段4：文档完善
1. 更新API文档
2. 编写使用指南
3. 添加示例代码

## 注意事项

1. **保持模型结构不变**: 不修改网络层数、隐藏层大小等模型参数
2. **保持训练逻辑不变**: 不修改损失函数、优化器等训练相关代码
3. **数据格式兼容**: 确保预处理后的数据格式与模型期望输入一致
4. **性能考虑**: 大规模数据处理时考虑内存和计算效率

通过以上适配计划，可以将新的 RCABench 数据格式成功适配到现有的 Eadro 模型中，同时保持模型的核心架构和训练逻辑不变。
